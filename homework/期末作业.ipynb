{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 期末作业\n",
    "\n",
    "**Notice!!!!!**\n",
    "\n",
    "1. 请将期末作业于**2021年1月7日，晚上24:00**之前提交至邮箱 liyan_zjgsu@163.com\n",
    "2. 请以jupyter notebook的形式提交, 文件的命名方式为**PythonFinal_班级_学号__姓名**（原始文件或压缩文件均需以此方式命名）\n",
    "3. 特别说明：为了便于给分以及避免漏判，请大家在写完代码之后注意：  \n",
    "（1）将代码按照各小题**模块化**  \n",
    "（2）尽可能多的写上**注释**，特别是对每个小题具体解法以及生成结果的说明\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**格式举例**\n",
    "\n",
    "```\n",
    "#### Answer for Q1 \n",
    "\n",
    "import tushare as ts\n",
    "……\n",
    "\n",
    "## Q1.1 请从tushareAPI获取2017年初至今所有银行股的收盘价。  \n",
    "\n",
    "your code block ## 行间注释\n",
    "\n",
    "print(result) ## 输出结果\n",
    "\n",
    "## Q1.2 ……\n",
    "\n",
    "……\n",
    "\n",
    "#### Answer for Q2\n",
    "……\n",
    "## Q2.1\n",
    "……\n",
    "## Q2.2\n",
    "……\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.**\n",
    "\n",
    "    1. 生成一个元素取值在[0, 100]中随机分布的10x4的二维数组A，生成一个元素取值符合正态分布的一维数组B，数组长度为40\n",
    "    2. 将B重塑为4x10的二维数组，计算矩阵C = AxB，C的逆矩阵以及C的行列式。\n",
    "    3. (a)以列表的形式返回矩阵C每一行中大于该行均值的数字 (b)以二维数组的形式返回上述数字所处的位置。\n",
    "    4. 从二维数组C生成一个DataFrame，将列名重命名为字母A~J\n",
    "    5. 将该DataFrame保存到本地C盘根目录下，文件名为rand_num.csv\n",
    "    \n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#### Answer for Q1\n",
    "## Q1.1\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "\n",
    "A = np.zeros([10, 4])\n",
    "for x in range(A.shape[0]):\n",
    "    for y in range(A.shape[1]):\n",
    "        A[x, y] = randint(0, 100)\n",
    "print(A)\n",
    "\n",
    "B = np.random.normal(size=[40])\n",
    "print(B)\n",
    "\n",
    "## Q1.2\n",
    "B = np.resize(B, new_shape=[4, 10])\n",
    "C = np.matmul(A, B)\n",
    "print(C)\n",
    "\n",
    "C_I = np.linalg.inv(C)\n",
    "print(C_I)\n",
    "\n",
    "C_det = np.linalg.det(C)\n",
    "print(C_det)\n",
    "\n",
    "## Q1.3\n",
    "# (a)\n",
    "C_mean = np.mean(C)\n",
    "a_list = []\n",
    "for x in range(C.shape[0]):\n",
    "    for y in range(C.shape[1]):\n",
    "        if C[x, y] > C_mean:\n",
    "            a_list.append(C[x, y])\n",
    "print(a_list)\n",
    "# (b)\n",
    "b_list = []\n",
    "for x in range(C.shape[0]):\n",
    "    for y in range(C.shape[1]):\n",
    "        if C[x, y] > C_mean:\n",
    "            b_list.append((x, y))\n",
    "print(b_list)\n",
    "\n",
    "## Q1.4\n",
    "df = pd.DataFrame(C)\n",
    "df.columns = list('ABCDEFGHIJ')\n",
    "print(df)\n",
    "\n",
    "## Q1.5\n",
    "df.to_csv(\"C:\\\\rand_num.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.**\n",
    "\n",
    "    1. 从tushareAPI提取所有上市公司的股票列表，从上市日期在2010年之前的股票中随机选出10支，从tushare获得它们的日线行情数据\n",
    "    2. 将这10支股票的成交量按照trade_date连接，取数据并集的方式合并成一个dataframe，列名为股票代码，行索引为trade_date\n",
    "    3. 随机选出两支股票，(a)对它们的收益率序列进行独立两样本t检验 (b)对它们的收盘价序列进行线性回归并输出结果\n",
    "    4. 对2中的表格，计算每一行的均值，并取出均值最大的10行\n",
    "    5. 将2中表格的nan值填充为对应列的均值，可视化该表格为折线图\n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Answer for Q2\n",
    "## Q2.1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tushare as ts\n",
    "import random\n",
    "from scipy.stats import ttest_ind, levene\n",
    "\n",
    "# 请在 tushare.pro 网站注册并且告知学生身份，可以取得你的token\n",
    "\n",
    "tushare_token = '1c8b06446534ae510c8c68e38fc248b99f89ac3814cb55645ae2be72'\n",
    "pro = ts.pro_api(tushare_token)\n",
    "\n",
    "data = pro.stock_basic(exchange='', list_status='L', fields='ts_code,symbol,name,area,industry,list_date')\n",
    "\n",
    "data = data[data['list_date'] > '20100101']  # 过滤掉上市时间不在2010年之前的股票\n",
    "\n",
    "ts_code_list = data.sample(n=10)['ts_code'].values.tolist()  # 随机选取10只股票\n",
    "\n",
    "daily_list = []\n",
    "for ts_code in ts_code_list:\n",
    "    daily_list.append(pro.daily(ts_code=ts_code))\n",
    "\n",
    "## Q2.2\n",
    "\n",
    "#  获取vol序列,并以日期为索引,以股票名命名\n",
    "vol_list = []\n",
    "for daily in daily_list:\n",
    "    daily.set_index(['trade_date'], inplace=True)\n",
    "    vol = daily['vol']\n",
    "    vol.name = daily['ts_code'][0]\n",
    "    vol_list.append(vol)\n",
    "\n",
    "vol_df = vol_list[0]\n",
    "for i in range(1, len(vol_list)):\n",
    "    vol_df = pd.merge(vol_df, vol_list[i], on=\"trade_date\", how=\"inner\")\n",
    "print(vol_df)\n",
    "\n",
    "## Q2.3\n",
    "# (a)\n",
    "\n",
    "# pct_change序列,同上\n",
    "pct_change_list = []\n",
    "for daily in daily_list:\n",
    "    pct_change = daily['pct_chg']\n",
    "    pct_change.name = daily['ts_code'][0]\n",
    "    pct_change_list.append(pct_change)\n",
    "\n",
    "pct_change_df = pct_change_list[0]\n",
    "for i in range(1, len(pct_change_list)):\n",
    "    pct_change_df = pd.merge(pct_change_df, pct_change_list[i], on=\"trade_date\", how=\"inner\")\n",
    "print(pct_change_df)\n",
    "\n",
    "two_ = random.sample(list(pct_change_df.columns), k=2)\n",
    "pct_change_df_two = pct_change_df[two_]\n",
    "\n",
    "# 计算两只股票的t检验\n",
    "X = pct_change_df_two[two_[0]]\n",
    "Y = pct_change_df_two[two_[1]]\n",
    "\n",
    "l_xy = levene(X, Y)\n",
    "\n",
    "if l_xy.pvalue > 0.05:\n",
    "    t_xy = ttest_ind(X, Y, equal_var=True)\n",
    "else:\n",
    "    t_xy = ttest_ind(X, Y, equal_var=False)\n",
    "print(\"T_statistic:\", t_xy.statistic, \"T_pvalue:\", t_xy.pvalue)\n",
    "\n",
    "# (b)\n",
    "\n",
    "# 用线性回归预测下一天的股价\n",
    "close_list = []\n",
    "for daily in daily_list:\n",
    "    series = daily['close']\n",
    "    series.name = daily['ts_code'][0]\n",
    "    close_list.append(series)\n",
    "\n",
    "close_df = close_list[0]\n",
    "for i in range(1, len(close_list)):\n",
    "    close_df = pd.merge(close_df, close_list[i], on=\"trade_date\", how=\"inner\")\n",
    "print(close_df)\n",
    "\n",
    "close_df_two = close_df[two_]\n",
    "X = close_df_two[two_[0]]\n",
    "Y = close_df_two[two_[1]]\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels import regression\n",
    "\n",
    "\n",
    "def linear_predict(series):\n",
    "    def regress_y(y):\n",
    "        x = np.arange(0, len(y))\n",
    "        x = sm.add_constant(x)\n",
    "        model = regression.linear_model.OLS(y, x).fit()\n",
    "        return model\n",
    "\n",
    "    model = regress_y(series)\n",
    "    b = model.params[0]\n",
    "    k = model.params[1]\n",
    "    return k * (len(series) + 1) + b\n",
    "\n",
    "\n",
    "X_predict = linear_predict(X)\n",
    "Y_predict = linear_predict(Y)\n",
    "print(\"X_predict:\", X_predict)\n",
    "print(\"Y_predict:\", Y_predict)\n",
    "\n",
    "## Q2.4\n",
    "\n",
    "# 选取top10\n",
    "vol_df24 = vol_df.copy()\n",
    "vol_df24['mean'] = vol_df24.mean(axis=1)\n",
    "vol_df24_mean_top10_index = vol_df24.loc[vol_df24['mean'].nlargest(n=10).index]\n",
    "print(vol_df24_mean_top10_index)\n",
    "\n",
    "## Q2.5\n",
    "vol_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "vol_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.**\n",
    "\n",
    "    1. 从 url=http://stock.finance.sina.com.cn/stock/go.php/vReport_List/kind/lastest/index.phtml?p=1 爬取1-50页的标题、报告类型、发布日期、机构四项信息，并将它们存入DataFrame中\n",
    "\n",
    "|title|type|date|institution|\n",
    "| -- | -- | -- | -- |\n",
    "| 标题1 | …… | …… | …… |\n",
    "| 标题2 | …… | …… | …… |\n",
    "……\n",
    "\n",
    "    2. 将该DataFrame存入本地的MySQL数据库中，存入的数据库名为sina，表名为report\n",
    "    3. 利用SQL语句统计上表中不同类型的记录数量，并从数据库中筛选 报告类型 为 行业 的表格\n",
    "    4. (a)对1中表格的 标题 这一列进行情感评分，并存入原始表格的sentiment列 (b)将情感评分的值按照 报告类型 求平均\n",
    "    5. 点击1中url页面里的标题，可以看到每篇研报的具体文字内容，请利用tf-idf和textrank算法提取该url页面所有研报内容权重最大的关键词，并以DataFrame格式输出\n",
    "    6. 绘制上述url页面中第一篇研报的词云图，注意过滤停用词。\n",
    "\n",
    "|title|tf-idf|textrank|\n",
    "| -- | -- | -- |\n",
    "| 标题1 | 关键字 | 关键字 |\n",
    "| 标题2 | 关键字 | 关键字 |\n",
    "……\n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Answer for Q3\n",
    "## Q3.1\n",
    "url = \"http://stock.finance.sina.com.cn/stock/go.php/vReport_List/kind/lastest/index.phtml?p=1\"\n",
    "url2 = \"http://stock.finance.sina.com.cn/stock/go.php/vReport_List/kind/lastest/index.phtml?p=2\"\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_list(url):\n",
    "    r = requests.get(url)\n",
    "    # 用BeautifulSoup解析网页,用GB18030编码,不然会乱吗\n",
    "    content = BeautifulSoup(r.content.decode(\"gb18030\"), \"html.parser\")\n",
    "    main_text = content.find(\"div\", class_=\"main\")\n",
    "    tr_list = main_text.find_all(\"tr\")[2:-1]\n",
    "    return tr_list\n",
    "\n",
    "\n",
    "tr_list = get_list(url) + get_list(url2)[:10]\n",
    "\n",
    "\n",
    "def get_attr(tr):\n",
    "    title = tr.find(\"a\")['title']\n",
    "    type = tr.contents[5].contents[0]\n",
    "    date = tr.contents[7].contents[0]\n",
    "    insitution = tr.find(\"span\").contents[0]\n",
    "    return title, type, date, insitution\n",
    "\n",
    "\n",
    "data_list = []\n",
    "for tr in tr_list:\n",
    "    data_list.append(get_attr(tr))\n",
    "df = pd.DataFrame(data_list, columns=['title', 'type', 'date', 'insitution'])\n",
    "print(df)\n",
    "\n",
    "## Q3.2\n",
    "\n",
    "import pymysql\n",
    "\n",
    "db = pymysql.connect(host=\"localhost\", user=\"root\", password=\"123456\", database=\"sina\")\n",
    "cursor = db.cursor()\n",
    "for data in data_list:\n",
    "    sql = \"insert into report(title, type, date, insitution) values ('%s', '%s', '%s', '%s')\" % (\n",
    "        data[0], data[1], data[2], data[3])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "db.commit()\n",
    "\n",
    "## Q3.3\n",
    "\n",
    "sql = \"select type, count(*) from report group by type\"\n",
    "res = cursor.execute(sql)\n",
    "print(res)\n",
    "\n",
    "sql = \"select * from report where type = '报告'\"\n",
    "res = cursor.execute(sql)\n",
    "print(res)\n",
    "\n",
    "## Q3.4\n",
    "# (a）\n",
    "from snownlp import SnowNLP\n",
    "\n",
    "# sentiment 打分\n",
    "df['sentiment'] = df['title'].apply(lambda x: SnowNLP(x).sentiments)\n",
    "\n",
    "# (b)\n",
    "sentiment_mean = df['sentiment'].mean(axis=0)\n",
    "print(sentiment_mean)\n",
    "\n",
    "\n",
    "## Q3.5\n",
    "def get_content(tr):\n",
    "    url = \"http:\" + tr.find(\"a\")['href']\n",
    "    r = requests.get(url)\n",
    "    content = BeautifulSoup(r.content.decode(\"gb18030\"), \"html.parser\")\n",
    "    main_text = content.find(\"div\", class_=\"blk_container\")\n",
    "    text = main_text.find(\"p\").text\n",
    "    return text.strip().replace(\"\\n\", \"\").replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\r\", \"\").replace(\" \", \"\")\n",
    "\n",
    "\n",
    "text_list = []\n",
    "text_all = \"\"\n",
    "\n",
    "for tr in tr_list:\n",
    "    text = get_content(tr)\n",
    "    text_list.append(text)\n",
    "    text_all += text\n",
    "\n",
    "import jieba.analyse as analyse\n",
    "\n",
    "print('TF-IDF')\n",
    "tf_idf_keyword_list = []\n",
    "for text in text_list:\n",
    "    for keyword, weight in analyse.extract_tags(text, topK=1, withWeight=True):\n",
    "        tf_idf_keyword_list.append(keyword)\n",
    "print('TextRank')\n",
    "text_rank_keyword_list = []\n",
    "for text in text_list:\n",
    "    for keyword, weight in analyse.textrank(text_all, topK=1, withWeight=True):\n",
    "        text_rank_keyword_list.append(keyword)\n",
    "\n",
    "tf_idf_keyword_series = pd.Series(tf_idf_keyword_list)\n",
    "text_rank_keyword_series = pd.Series(text_rank_keyword_list)\n",
    "print(tf_idf_keyword_series)\n",
    "print(text_rank_keyword_series)\n",
    "\n",
    "## Q3.6\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "my_wordcloud = WordCloud(font_path=\"SimHei.ttf\").generate(text_list[0])  # 生成词云\n",
    "\n",
    "plt.imshow(my_wordcloud)  # 绘制词云图片\n",
    "plt.axis(\"off\")  # 不显示坐标轴\n",
    "plt.show()  # 显示图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** \n",
    "\n",
    "    1. 请从tushareAPI获取2017年初至今所有银行股的收盘价。  \n",
    "    2. 计算上述股票收盘价的收益率序列的相关矩阵，并绘制热图。  \n",
    "    3. 请在最大回撤最小的前50%支股票中找出下行风险最小的前50%支股票。  \n",
    "    4. 绘制总标题为中文“银行股”，2x1的子图，调整图片大小为20x20。\n",
    "    子图一：将4中筛选出的股票价格序列起始点均平移到0点后，以日期为横坐标，收盘价为纵坐标绘制折线图，不显示横坐标刻度和标签，在画面左上角添加图例，为图片添加网格并设置50%的透明度。  \n",
    "    子图二：计算个股收盘价序列的均值作为行业指数，计算该行业指数的6日的指数平均线ema，以及6日移动窗口中的标准差std6，在图中绘制原始行业指数和ema，并以ema+std6和ema-std6为上下边界进行填充，填充的颜色为红色，透明度为0.1，请在图中以适当的间距显示日期。  \n",
    "    \n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Answer for Q4\n",
    "## Q4.1\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tushare as ts\n",
    "\n",
    "tushare_token = '1c8b06446534ae510c8c68e38fc248b99f89ac3814cb55645ae2be72'\n",
    "pro = ts.pro_api(tushare_token)\n",
    "data = pro.stock_basic(exchange='', list_status='L', fields='ts_code,symbol,name,area,industry,list_date')\n",
    "data = data[data['list_date'] > '20170101']\n",
    "data = data[data['industry'] == '银行']\n",
    "ts_code_list = data['ts_code'].values.tolist()\n",
    "\n",
    "daily_list = []\n",
    "for ts_code in ts_code_list:\n",
    "    daily_list.append(pro.daily(ts_code=ts_code).dropna())\n",
    "\n",
    "close_list = []\n",
    "for daily in daily_list:\n",
    "    daily = daily.set_index(['trade_date'], inplace=False)\n",
    "    close_list.append(daily['close'].rename(daily['ts_code'][0]))\n",
    "close_df = pd.concat(close_list, axis=1)\n",
    "print(close_df)\n",
    "\n",
    "## Q4.2\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for daily in daily_list:\n",
    "    close_pct_change = daily[['pct_chg', 'close']]\n",
    "    f, ax = plt.subplots(figsize=(14, 10))\n",
    "    corrdf = close_pct_change.corr()\n",
    "    sns.heatmap(corrdf, cmap='RdBu', linewidths=0.05, ax=ax)\n",
    "\n",
    "    # 设置Axes的标题\n",
    "    ax.set_title(daily['ts_code'][0])\n",
    "    plt.show()\n",
    "\n",
    "pct_change_list = []\n",
    "for daily in daily_list:\n",
    "    pct_change = daily['pct_chg']\n",
    "    pct_change.name = daily['ts_code'][0]\n",
    "    pct_change_list.append(pct_change)\n",
    "\n",
    "pct_change_df = pd.concat(pct_change_list, axis=1)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(14, 10))\n",
    "corrdf = pct_change_df.corr()\n",
    "sns.heatmap(corrdf, cmap='RdBu', linewidths=0.05, ax=ax)\n",
    "\n",
    "# 设置Axes的标题\n",
    "ax.set_title('Correlation between stocks')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Q4.3\n",
    "def MaxDrawdown(returns):\n",
    "    l = np.argmax((np.maximum.accumulate(returns) - returns) / np.maximum.accumulate(returns))\n",
    "    k = np.argmax(returns[:l])\n",
    "    return (returns[k] - returns[l]) / (returns[l])\n",
    "\n",
    "\n",
    "def cal_half_def(returns):\n",
    "    for i in range(len(returns)):\n",
    "        returns[i] = returns[0] - returns[i]\n",
    "    mu = returns.mean()  # 这里使用的是均值\n",
    "    temp = returns[returns < mu]\n",
    "    half_deviation = (sum((temp - mu) ** 2) / len(temp)) ** 0.5\n",
    "    return half_deviation\n",
    "\n",
    "\n",
    "stocks = []\n",
    "for daily in daily_list:\n",
    "    close_list = daily['close'].values.tolist()\n",
    "    close_list.reverse()\n",
    "    maximum_pullback = MaxDrawdown(close_list)\n",
    "    half_deviation = cal_half_def(np.array(close_list))\n",
    "    print(maximum_pullback, half_deviation)\n",
    "    stocks.append((daily['ts_code'][0], maximum_pullback, half_deviation))\n",
    "stocks.sort(key=lambda x: x[1])\n",
    "stocks = stocks[:len(stocks) // 2]\n",
    "stocks.sort(key=lambda x: x[2])\n",
    "stocks = stocks[:len(stocks) // 2]\n",
    "for stock in stocks:\n",
    "    print(stock[0])\n",
    "\n",
    "## Q4.4\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 绘制子图\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 20))\n",
    "close_df = close_df.dropna().iloc[::-1]\n",
    "close_df_sub = close_df - close_df.iloc[0, :]\n",
    "\n",
    "ax[0].plot(close_df_sub)\n",
    "ax[0].set_title('Close Price')\n",
    "close_df['mean'] = close_df.mean(axis=1)\n",
    "\n",
    "\n",
    "def get_ema_std(six_days):\n",
    "    ema = sum(six_days) / len(six_days)\n",
    "    std = sum((six_days - ema) ** 2) / len(six_days)\n",
    "    return ema, std\n",
    "\n",
    "\n",
    "ema_list = []\n",
    "\n",
    "for i in range(6, len(close_df['mean'])):\n",
    "    six_days = close_df['mean'][i - 6:i]\n",
    "    ema, std = get_ema_std(six_days)\n",
    "    ema_list.append(ema)\n",
    "\n",
    "# 一些精细的设置 学习成本太高\n",
    "close_df = close_df[6:]\n",
    "close_df['ema'] = ema_list\n",
    "close_df_mean_ema = close_df[['mean', 'ema']]\n",
    "close_df_mean_ema.plot(ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q++**\n",
    "\n",
    "    画出000001.SZ的k线图，对其使用MACD策略，计算净值曲线，夏普比率，最大回撤及下行风险。\n",
    "    \n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Answer for Q++\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import talib\n",
    "import tushare as ts\n",
    "from matplotlib import ticker\n",
    "from mplfinance.original_flavor import candlestick_ochl\n",
    "\n",
    "tushare_token = '1c8b06446534ae510c8c68e38fc248b99f89ac3814cb55645ae2be72'\n",
    "pro = ts.pro_api(tushare_token)\n",
    "code = \"000001.SZ\"\n",
    "df = pro.daily(ts_code=code)\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = df.query('trade_date >= \"20171001\"').reset_index()  # 选取2017年10月1日后的数据\n",
    "df2 = df2.sort_values(by='trade_date', ascending=True)  # 原始数据按照日期降序排列\n",
    "df2['dates'] = np.arange(0, len(df2))  # len(df2)指记录数\n",
    "fig, ax = plt.subplots(figsize=(20, 9))\n",
    "fig.subplots_adjust(bottom=0.2)  # 控制子图\n",
    "###candlestick_ochl()函数的参数\n",
    "# ax 绘图Axes的实例\n",
    "# quotes  序列（时间，开盘价，收盘价，最高价，最低价） 时间是float类型，date必须转换为float\n",
    "# width    图像中红绿矩形的宽度,代表天数\n",
    "# colorup  收盘价格大于开盘价格时的颜色\n",
    "# colordown   低于开盘价格时矩形的颜色\n",
    "# alpha      矩形的颜色的透明度\n",
    "candlestick_ochl(ax, quotes=df2[['dates', 'open', 'close', 'high', 'low']].values,\n",
    "                 width=0.55, colorup='r', colordown='g', alpha=0.95)\n",
    "date_tickers = df2['trade_date'].values\n",
    "\n",
    "\n",
    "def format_date(x, pos):\n",
    "    if (x < 0) or (x > len(date_tickers) - 1):\n",
    "        return ''\n",
    "    return date_tickers[int(x)]\n",
    "\n",
    "\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(format_date))  # 按一定规则选取并在水平轴上显示时间刻度\n",
    "plt.xticks(rotation=30)  # 设置日期刻度旋转的角度\n",
    "ax.set_ylabel('交易价格')\n",
    "plt.title(code)\n",
    "plt.grid(True)  # 添加网格，可有可无，只是让图像好看一些\n",
    "plt.xlabel('交易日期')\n",
    "plt.show()\n",
    "\n",
    "## MACD\n",
    "close = df2['close'].values\n",
    "macd = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "print(macd)\n",
    "\n",
    "##\n",
    "\n",
    "\n",
    "## 计算夏普比率\n",
    "df['ex_pct_close'] = df['pct_chg'] - 0.04 / 252\n",
    "sharpeRatio = (df['ex_pct_close'].mean() * math.sqrt(252)) / df['ex_pct_close'].std()\n",
    "print(\"sharpeRatio:\", sharpeRatio)\n",
    "\n",
    "\n",
    "## 最大回撤\n",
    "def MaxDrawdown(returns):\n",
    "    l = np.argmax((np.maximum.accumulate(returns) - returns) / np.maximum.accumulate(returns))\n",
    "    k = np.argmax(returns[:l])\n",
    "    return (returns[k] - returns[l]) / (returns[l])\n",
    "\n",
    "\n",
    "maximumPullback = MaxDrawdown(close)\n",
    "print(\"maximumPullback:\", maximumPullback)\n",
    "\n",
    "\n",
    "def cal_half_def(returns):\n",
    "    for i in range(len(returns)):\n",
    "        returns[i] = returns[0] - returns[i]\n",
    "    mu = returns.mean()  # 这里使用的是均值\n",
    "    temp = returns[returns < mu]\n",
    "    half_deviation = (sum((temp - mu) ** 2) / len(temp)) ** 0.5\n",
    "    return half_deviation\n",
    "\n",
    "# 下行风险\n",
    "half_deviation = cal_half_def(np.array(close))\n",
    "print(\"half_deviation:\", half_deviation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}